{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot function ASTs\n",
    "\n",
    "# TODO: FIRST THING TOMORROW - need to draw the GNN diagram, use this as a BLUEPRINT\n",
    "# for the model design\n",
    "\n",
    "# - I expect it to evolve as I go, but need to START SOMEWHERE\n",
    "# - Annotate what the feature vectors look like for nodes\n",
    "# - How many hops away do we need to gather information (GNN depth)?\n",
    "# - What virtual edges might we insert? (e.g. connect all instances of target variable)\n",
    "# - Should we MASK OUT the target variable?\n",
    "\n",
    "# also...\n",
    "# - look at function proto recovery accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Execute this notebook headlessly using something like:\n",
    "#\n",
    "# EXP_FOLDER=~/test_builds/coreutils.exp/ jupyter nbconvert --to html --execute characterize_dataset.ipynb --no-input\n",
    "#\n",
    "\n",
    "MANUAL_EXP_FOLDER = Path.home()/'test_builds'/'astera3.exp'\n",
    "\n",
    "# take the env-var-specified experiment if present\n",
    "EXP_FOLDER = Path(os.environ['EXP_FOLDER']) if 'EXP_FOLDER' in os.environ else MANUAL_EXP_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/cls0027/test_builds/astera3.exp/rundata/run1/0.fighter/ast_dumps/stripped/Func143603-FUN_00143603.json')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import wildebeest as wdb\n",
    "# wdb.get_experiment_names()\n",
    "ast_json = EXP_FOLDER/'rundata'/'run1'/'0.fighter'/'ast_dumps'/'stripped'/'Func143603-FUN_00143603.json'\n",
    "[x for x in (EXP_FOLDER/'rundata'/'run1'/'0.fighter'/'ast_dumps'/'stripped').iterdir() if '143603' in x.name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for PyG Model\n",
    "*Sticking this here for now for sake of time...*\n",
    "\n",
    "We need to **quickly** write the code to take our data tables and convert each variable into the format ready to go for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_kind_ids = {\n",
    "    'ArraySubscriptExpr': 0,\n",
    "    'BinaryOperator': 1,\n",
    "    'BreakStmt': 2,\n",
    "    'BuiltinType': 3,\n",
    "    'CallExpr': 4,\n",
    "    'CaseStmt': 5,\n",
    "    'CharacterLiteral': 6,\n",
    "    'CompoundStmt': 7,\n",
    "    'ConstantArrayType': 8,\n",
    "    'ConstantExpr': 9,\n",
    "    'CStyleCastExpr': 10,\n",
    "    'DeclRefExpr': 11,\n",
    "    'DeclStmt': 12,\n",
    "    'DoStmt': 13,\n",
    "    'EnumDecl': 14,\n",
    "    'EnumConstantDecl': 15,\n",
    "    'EnumType': 16,\n",
    "    'FieldDecl': 17,\n",
    "    'FloatingLiteral': 18,\n",
    "    'ForStmt': 19,\n",
    "    'FunctionDecl': 20,\n",
    "    'FunctionType': 21,\n",
    "    'GotoStmt': 22,\n",
    "    'IfStmt': 23,\n",
    "    'IntegerLiteral': 24,\n",
    "    'LabelStmt': 25,\n",
    "    'MemberExpr': 26,\n",
    "    'NullNode': 27,\n",
    "    'ParenExpr': 28,\n",
    "    'ParmVarDecl': 29,\n",
    "    'PointerType': 30,\n",
    "    'RecordDecl': 31,\n",
    "    'ReturnStmt': 32,\n",
    "    'StringLiteral': 33,\n",
    "    'StructField': 34,\n",
    "    'StructType': 35,\n",
    "    'SwitchStmt': 36,\n",
    "    'TranslationUnitDecl': 37,\n",
    "    'Type': 38,\n",
    "    'TypedefDecl': 39,\n",
    "    'TypedefType': 40,\n",
    "    'UnaryOperator': 41,\n",
    "    'ValueDecl': 42,\n",
    "    'VarDecl': 43,\n",
    "    'VoidType': 44,\n",
    "    'WhileStmt': 45,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astlib\n",
    "from astlib.color_ast import highlight_var_refs, highlight_khop_neighborhood\n",
    "from astlib.find_all_references import *\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "run_folder = EXP_FOLDER/'rundata'/'run1'\n",
    "\n",
    "# list((EXP_FOLDER/'rundata'/'run1').iterdir())\n",
    "# list(run_folder.glob('*.csv'))\n",
    "\n",
    "# def generate_dtpredict_dataset(run_folder:Path):\n",
    "locals_df = pd.read_csv(run_folder/'locals.csv')\n",
    "\n",
    "# NOTE: need to go back to AST JSON directly to read it back in (we have to use the whole thing anyway)\n",
    "# NOTE: we could be a bit more efficient by passing the ASTs we already have in-memory to this function\n",
    "# instead of reading them back again from the file...\n",
    "# TODO: would be nice to just have the AST filenames here in the functions table though\n",
    "funcs_df = pd.read_csv(run_folder/'functions.csv')\n",
    "\n",
    "\n",
    "# addr = locals_df.FunctionStart.unique()[0]\n",
    "# ast_file = funcs_df[funcs_df.FunctionStart==addr].AstJson_Strip.iloc[0]\n",
    "\n",
    "# ast, slib = astlib.json_to_ast(ast_file)\n",
    "\n",
    "# # locals_df[locals_df.FunctionStart]\n",
    "# for i, x in enumerate(locals_df.groupby(['BinaryId', 'FunctionStart'])):\n",
    "#     # print(x)\n",
    "#     if i > 5:\n",
    "#         break\n",
    "\n",
    "# x[1]\n",
    "\n",
    "# AHA! DataFrameGroupBy object behaves like an iterable of tuples:\n",
    "    # [0]: tuple of values for the columns you grouped by\n",
    "    # [1]: corresponding data frame with this subset of the data\n",
    "\n",
    "##########################################################\n",
    "# TODO: write a function that converts the local variables into pyg format for a given function dataframe\n",
    "# - then I can pass this function to a groupby() that splits the data by unique binary/function combos\n",
    "#   and it will work as intended\n",
    "##########################################################\n",
    "df_list = locals_df.groupby(['BinaryId', 'FunctionStart']).pipe(lambda gb: [x[1] for x in gb])\n",
    "# --------------------\n",
    "# TODO: for all locals in this function (start here, we'll see how it evolves)\n",
    "# 1. Find all references to the local (see below)\n",
    "# 2. Extract those statements in which the reference \"participates\" (see below)\n",
    "# 3. Join the target nodes all into one, preserving existing connections\n",
    "#       - ok to do this \"directly\" on the data, we read it from the file and won't modify original file\n",
    "# 4. Write this resulting graph to a file ready to go for pyg\n",
    "#       - how does pyg want this? just a json file? look at pyg tutorials\n",
    "#\n",
    "#       >>> only need to save the data/features we need for the model (and just enough metadata\n",
    "#           to refer back to the func/var of interest)\n",
    "##########################################################\n",
    "\n",
    "# TODO: convert this to a function we call using pipe() above\n",
    "df = df_list[33]\n",
    "\n",
    "addr = df.FunctionStart.iloc[0]\n",
    "ast_file = funcs_df[funcs_df.FunctionStart==addr].iloc[0].AstJson_Strip\n",
    "\n",
    "ast, slib = astlib.json_to_ast(ast_file)\n",
    "df.drop(columns=['LocType_Debug','LocRegName_Debug','LocOffset_Debug','LocType_Strip','LocRegName_Strip','LocOffset_Strip'])\n",
    "\n",
    "# -------------------------------------------\n",
    "# TODO: for each local... i in range(len(df))\n",
    "name_strip = df.iloc[0].Name_Strip\n",
    "# -------------------------------------------\n",
    "\n",
    "fbody = ast.inner[-1].inner[-1]\n",
    "\n",
    "# NOTE: this is the simplest approach - just taking k-hop neighborhoods for\n",
    "# each reference\n",
    "# --> however, limiting neighborhoods to staying within the statement seems\n",
    "#     better since other statements are independent!\n",
    "#     (and we know this...why confuse the model?)\n",
    "# decl_ref_nodes = FindAllVarRefs(name_strip).visit(fbody)\n",
    "# node = decl_ref_nodes[0]\n",
    "# for node in decl_ref_nodes:\n",
    "#     display(node.parent.parent.parent.render(format_node=highlight_khop_neighborhood(node, 2, 'red')))\n",
    "\n",
    "# statements = FindAllStatementsContainingVar(name_strip).collect_statement_set(fbody)\n",
    "# statements\n",
    "\n",
    "# zero out parent connection to ensure we don't reach outside\n",
    "# the statement\n",
    "# for s in statements:\n",
    "#     s.statement_node.parent = None\n",
    "\n",
    "# for s in statements:\n",
    "    # display(s.statement_node.render(format_node=highlight_khop_neighborhood(s.refexprs, 2)))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# TODO: go back to pyg tutorials and see what format pyg wants...then make this fit!\n",
    "# ----------------------------------------------------------------\n",
    "# 1. node list\n",
    "#   - target node at 0th position\n",
    "#   - assign indices 0 -> n-1 (node.pyg_idx = next_idx++) as we add nodes\n",
    "# 2. edge_index\n",
    "#   - refer to node endpoints by index (above)\n",
    "#   - add bidirectional edges probably...\n",
    "\n",
    "# FIXME: later on, we will add these things, but for now:\n",
    "# - No edge types\n",
    "# - NODE TYPE is only node feature\n",
    "\n",
    "# s = statements[2]\n",
    "# TODO: need to map possible truth data types to enums (we will then one-hot them)\n",
    "\n",
    "\n",
    "######## OLD: don't need to FIND statements ahead of time now\n",
    "# # TODO: we don't even need statements anymore! lol\n",
    "# # --> just find all variable references and don't COLLECT any neighbors\n",
    "# #     outside the statement (dynamically we can check with node.is_statement)\n",
    "# statements = FindAllStatementsContainingVar(self.var_name).collect_statement_set(fbody)\n",
    "# # zero out parent connection to ensure we don't reach outside the statement\n",
    "# for s in statements:\n",
    "#     s.statement_node.parent = None\n",
    "# ref_exprs = [r for s in statements for r in s.refexprs]\n",
    "\n",
    "# each refexpr is an independent sample\n",
    "# ref_exprs = [r for s in statements for r in s.refexprs]\n",
    "\n",
    "####################### ---------------------######################\n",
    "####################### TODO: pick up here...######################\n",
    "####################### ---------------------######################\n",
    "# each ref_expr will be joined into node #0 in our graph\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "MAX_HOPS = 3\n",
    "\n",
    "def encode(node:ASTNode) -> torch.Tensor:\n",
    "    '''Encodes an ASTNode into a feature vector'''\n",
    "    return F.one_hot(torch.tensor(node_kind_ids[node.kind]), len(node_kind_ids))\n",
    "\n",
    "class VariableGraphBuilder:\n",
    "    '''\n",
    "    Builds the variable graph that will be used as input to the model.\n",
    "\n",
    "    Currently supports only locals and params\n",
    "    '''\n",
    "    def __init__(self, var_name:str, ast:ASTNode, slib:Dict[int, astlib.StructDef]):\n",
    "        '''\n",
    "        var_name: Name of the target variable\n",
    "        ast: AST for the function this variable resides in\n",
    "        slib: Struct library for this AST (as returned by astlib.json_to_ast() with\n",
    "              the AST object)\n",
    "        '''\n",
    "        self.__reset_state()\n",
    "        self.var_name = var_name\n",
    "\n",
    "        self.ast = ast\n",
    "        self.slib = slib\n",
    "\n",
    "    def __reset_state(self):\n",
    "        self._next_idx = 0\n",
    "        self.node_list = []\n",
    "        self.edge_index = []\n",
    "\n",
    "    def build_variable_graph(self, max_hops:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        Generates the variable graph and returns it as a\n",
    "        [node_list, edge_index] tuple of tensors\n",
    "        '''\n",
    "        self.__reset_state()\n",
    "\n",
    "        fbody = self.ast.inner[-1].inner[-1]\n",
    "        ref_exprs = FindAllVarRefs(self.var_name).visit(fbody)\n",
    "\n",
    "        # each refexpr is an independent sample that needs to be merged\n",
    "        # into our target node 0\n",
    "\n",
    "        # 1. add node 0/merge ref_exprs into special target node\n",
    "        for r in ref_exprs:\n",
    "            r.pyg_idx = self._next_idx\n",
    "        self._next_idx += 1\n",
    "\n",
    "        self.node_list = [encode(ref_exprs[0])]  # pick one and encode it, they are identical\n",
    "\n",
    "        # edge index starts out as a list of strings of the form \"<start_idx>,<stop_idx>\"\n",
    "        # so we can prevent adding duplicate edges. Then we convert to tensor form once finished\n",
    "        self.edge_index = []\n",
    "\n",
    "        # add other nodes by following edges up to MAX HOPS\n",
    "        for r in ref_exprs:\n",
    "            # collect subgraph connected to r (we've already got the reference node captured)\n",
    "            self.collect_node_neighbors(r, max_hops)\n",
    "\n",
    "        # collect edge indices into flat list, then reshape into (N, 2)\n",
    "        flat_list = [int(idx) for edge_str in self.edge_index for idx in edge_str.split(',')]\n",
    "        N = int(len(flat_list)/2)\n",
    "        self.edge_index = torch.tensor(flat_list, dtype=torch.long).reshape((N, 2))\n",
    "\n",
    "        # torch-ify :)\n",
    "        self.node_list = torch.stack(self.node_list)\n",
    "        self.edge_index = self.edge_index.t().contiguous()\n",
    "\n",
    "        return self.node_list, self.edge_index\n",
    "\n",
    "    def add_node(self, node:ASTNode):\n",
    "        if not hasattr(node, 'pyg_idx'):\n",
    "            # this is a new node - add it\n",
    "            node.pyg_idx = self._next_idx\n",
    "            self._next_idx += 1\n",
    "            self.node_list.append(encode(node))\n",
    "\n",
    "    def _get_edge_string(self, start_idx:int, stop_idx:int):\n",
    "        return f'{start_idx},{stop_idx}'\n",
    "\n",
    "    def add_edge(self, start_node:ASTNode, end_node:ASTNode, bidirectional:bool):\n",
    "        fwd_edge = self._get_edge_string(start_node.pyg_idx, end_node.pyg_idx)\n",
    "        if fwd_edge not in self.edge_index:\n",
    "            self.edge_index.append(fwd_edge)\n",
    "\n",
    "        if bidirectional:\n",
    "            back_edge = self._get_edge_string(end_node.pyg_idx, start_node.pyg_idx)\n",
    "            if back_edge not in self.edge_index:\n",
    "                self.edge_index.append(back_edge)\n",
    "\n",
    "    def collect_node_neighbors(self, node:ASTNode, k:int):\n",
    "        '''\n",
    "        Collect the k-hop neighborhood of node (not including node) staying\n",
    "        within the current statement\n",
    "        '''\n",
    "        if k <= 0:\n",
    "            return\n",
    "\n",
    "        # if we are at a statement node, don't go up outside this statement\n",
    "        if node.parent and not node.is_statement:\n",
    "            self.add_node(node.parent)\n",
    "            self.add_edge(node, node.parent, bidirectional=True)\n",
    "            self.collect_node_neighbors(node.parent, k-1)\n",
    "\n",
    "        for child in node.inner:\n",
    "            self.add_node(child)\n",
    "            self.add_edge(node, child, bidirectional=True)\n",
    "            self.collect_node_neighbors(child, k-1)\n",
    "\n",
    "# ref_exprs\n",
    "# node_list = torch.stack([encode(x) for x in ref_exprs])\n",
    "# node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<astlib.ast.CompoundStmt object at 0x7f6f81b6dbe0>\n"
     ]
    }
   ],
   "source": [
    "# ast.inner[-1].inner[-1].inner[-3].render()\n",
    "print(ast.inner[-1].inner[-1].inner[-3].inner[2].inner[1].parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = VariableGraphBuilder(name_strip, ast, slib)\n",
    "node_list, edge_index = builder.build_variable_graph(MAX_HOPS)\n",
    "node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  2,  0,  3,  3,  4,  4,  5,  4,  6,  3,  7,  7,  8,  0,  9,\n",
       "          9, 10, 10,  0, 10, 11,  0, 12, 12, 13, 13, 14, 12, 15,  0, 16, 16, 17,\n",
       "         17, 18, 17, 19,  0, 20, 20, 21, 21, 22, 21, 23,  0, 24, 24, 25, 25, 26,\n",
       "         25, 20, 24, 27,  0, 28, 28, 29, 29, 30, 28, 31,  0, 32, 32, 33,  0, 34,\n",
       "         34, 35, 35, 36, 34, 37,  0, 38, 38, 39, 38, 40, 38, 41, 38, 42, 38, 43,\n",
       "         38, 44,  0, 45, 45, 46, 46, 47, 45, 48,  0, 49, 49, 50, 50, 51, 49, 52,\n",
       "          0, 53, 53, 54, 54, 55, 53, 56],\n",
       "        [ 1,  0,  2,  1,  3,  0,  4,  3,  5,  4,  6,  4,  7,  3,  8,  7,  9,  0,\n",
       "         10,  9,  0, 10, 11, 10, 12,  0, 13, 12, 14, 13, 15, 12, 16,  0, 17, 16,\n",
       "         18, 17, 19, 17, 20,  0, 21, 20, 22, 21, 23, 21, 24,  0, 25, 24, 26, 25,\n",
       "         20, 25, 27, 24, 28,  0, 29, 28, 30, 29, 31, 28, 32,  0, 33, 32, 34,  0,\n",
       "         35, 34, 36, 35, 37, 34, 38,  0, 39, 38, 40, 38, 41, 38, 42, 38, 43, 38,\n",
       "         44, 38, 45,  0, 46, 45, 47, 46, 48, 45, 49,  0, 50, 49, 51, 50, 52, 49,\n",
       "         53,  0, 54, 53, 55, 54, 56, 53]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astlib\n",
    "from astlib.color_ast import highlight_var_refs\n",
    "\n",
    "ast, slib = astlib.json_to_ast(ast_json)\n",
    "ast.inner[-1].inner[-1].inner[8].inner[0].inner\n",
    "\n",
    "# if node.kind == highlight_kind:\n",
    "#             attrs.font_color = highlight_color\n",
    "# def highlight_var(varname:str):\n",
    "#     def do_highlight(node, attrs):\n",
    "#         if node.kind == 'DeclRefExpr' and node.referencedDecl.name == varname:\n",
    "#             attrs.font_color = 'red'\n",
    "#     return do_highlight\n",
    "\n",
    "ast.render(format_node=highlight_var_refs('param_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdecl = ast.inner[-1].inner[0]\n",
    "pvdecl.name\n",
    "\n",
    "fbody = ast.inner[-1].inner[-1]\n",
    "from astlib.find_all_references import *\n",
    "\n",
    "res = FindAllVarRefs('param_1').visit(fbody)\n",
    "# res[0].parent.parent.parent.parent.parent.parent\n",
    "statements = FindAllStatementsContainingVar('param_1').collect_statement_set(fbody)\n",
    "statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in statements:\n",
    "    display(s.render(format_node=highlight_var_refs('param_1')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
