{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_colwidth', 20)   # JSON columns make things look weird in notebook without this\n",
    "\n",
    "from datatype_recovery.models.dataset.balance import plot_dataset_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatype_recovery.models.dataset.encoding import TypeSequence\n",
    "\n",
    "#pd.DataFrame([(\",\".join(x), 0.0) for x in TypeSequence().valid_type_sequences_for_len(2)], columns=['TypeSeq_Debug', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# parameters\n",
    "# dataset_path = Path.home()/'datasets/trainset_astera_full_5hops_nocomp'\n",
    "# dataset_path = Path.home()/'datasets/trainset_astera_ffmpeg'\n",
    "# dataset_path = Path.home()/'datasets/coreutils_full_5hops'\n",
    "dataset_path = Path.home()/'datasets/trainset_bigger'\n",
    "drop_comp = True\n",
    "drop_return_types = True    # right now TypeSeqDatset is doing this\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# context: talk, notebook, paper, poster\n",
    "# palette: muted, Paired, hls, husl, pastel, bright, deep, dark, colorblind\n",
    "sns.set_theme(style='whitegrid', context='notebook', palette='muted')\n",
    "\n",
    "var_df, bal_df = plot_dataset_balance(dataset_path, drop_comp, drop_return_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(bal_df.index[i], val) for i, val in enumerate(bal_df.sum(axis=1))]\n",
    "\n",
    "# bal_df[~bal_df[1].isna()]\n",
    "lookup = {}\n",
    "for i in range(1, bal_df.columns.max()+1):\n",
    "    lookup[str(i)] = [(bal_df.index[i], val) for i, val in enumerate(bal_df[i])]\n",
    "lookup.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_typeseq_len(bal_df)\n",
    "#plot_full_dataset_balance(bal_df)\n",
    "test = bal_df*len(var_df)\n",
    "var_df.groupby('TypeSeq_Debug').count()[['BinaryId']].sort_values('BinaryId')\n",
    "\n",
    "from datatype_recovery.models.dataset.encoding import TypeSequence\n",
    "\n",
    "# keep all 1-element sequences, apply the projection from 2-element sequences and up\n",
    "\n",
    "\n",
    "\n",
    "# maybe exclude void from consideration after 2-seq?\n",
    "\n",
    "valid_sequences = TypeSequence().valid_type_sequences_for_len(3)\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "\n",
    "    # if len(seq) > 1:\n",
    "    #     projected_seq.append([projection_2ndlevel[x] if x in projection_2ndlevel else x for x in seq])\n",
    "    # else:\n",
    "    #     projected_seq.append([projection_1stlevel[x] if x in projection_1stlevel else x for x in seq])\n",
    "\n",
    "\n",
    "# sorted(list(x.split(',') for x in set(\",\".join(x) for x in projected_seq)), key=lambda x: f'{len(x)}{\",\".join(x)}')\n",
    "projected_seq = [project_typesequence(s, projection) for s in valid_sequences]\n",
    "projected_seq\n",
    "\n",
    "var_df.TypeSeq_Debug\n",
    "var_df['Projection'] = var_df.TypeSeq_Debug.apply(lambda x: \",\".join(project_typesequence(x.split(','), projection, drop_after_len=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = var_df.loc[var_df.TypeSeq_Debug!='FUNC',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(set(\",\".join(x) for x in projected_seq))\n",
    "proj_classes = var_df.groupby('Projection').count()[['BinaryId']].index.to_list()\n",
    "\n",
    "all_proj_classes = set([\",\".join(x) for x in projected_seq])\n",
    "\n",
    "len(all_proj_classes)\n",
    "\n",
    "all_proj_classes - set(proj_classes)\n",
    "min_value = var_df.groupby('Projection').count().BinaryId.sort_values().iloc[0]\n",
    "print(f'Balance with {min_value} samples per class')\n",
    "\n",
    "var_df.groupby('Projection').count().BinaryId.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df[var_df.TypeSeq_Debug.isin(['ushort','STRUCT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = var_df.groupby('Projection').sample(n=min_value, random_state=33)\n",
    "percent_dropped = 100-len(balanced_df)/len(var_df)*100\n",
    "print(f'Dropped {percent_dropped:.2f}% of the original dataset (from {len(var_df):,} down to {len(balanced_df):,})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df\n",
    "dataset = load_dataset_from_path(dataset_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].varid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['VarID'] = balanced_df.apply(lambda x: (x.BinaryId, x.FunctionStart, x.Signature, x.Vartype), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_varids = balanced_df.VarID.to_list()\n",
    "\n",
    "balanced_indices = [i for i in range(len(dataset)) if dataset[i].varid in balanced_varids]\n",
    "balanced_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.groupby('TypeSeq_Debug').count()[['BinaryId']].plot(kind='bar', figsize=(18,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.groupby('Projection').count()[['BinaryId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    print(f'{len(TypeSequence().valid_type_sequences_for_len(i))} valid types for sequence of length {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 4\n",
    "num_over_maxlen = counts[counts.TypeSeqLen>max_seq_len].BinaryId.sum()\n",
    "print(f'{num_over_maxlen:,} of {len(var_df):,} variables exceeded max length of {max_seq_len} ({num_over_maxlen/len(var_df)*100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df.loc[:,'TSL_Debug'] = var_df.TypeSeq_Debug.apply(lambda ts: len(ts.split(',')))\n",
    "var_df[(var_df.HasDWARF)&(var_df.TSL_Debug<=1)].groupby('TypeSeq_Debug').count().sort_values('BinaryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_idx = sorted(counts.index, key=lambda x: f'{len(x.split(\",\"))}{x}')\n",
    "max_true_len = var_df.TypeSeq_Debug.apply(lambda ts: len(ts.split(','))).max()\n",
    "var_df[var_df.TypeSeq_Debug.apply(lambda ts: len(ts.split(',')) >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_df = (counts.loc[ordered_idx][['BinaryId']]/len(var_df)*100)\n",
    "# .plot(kind='bar')\n",
    "perc_df[perc_df.BinaryId>=4].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_df.sort_values('BinaryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df[var_df.TypeSeq_Debug=='FUNC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalize Ghidra's FUNC var types to be PTR,FUNC for consistency\n",
    "\n",
    "from varlib.datatype import datatype_from_json_str, PointerType\n",
    "\n",
    "ftype = datatype_from_json_str(var_df[var_df.TypeSeq_Debug=='FUNC'].TypeJson_Debug.iloc[0])\n",
    "ftype\n",
    "PointerType(ftype, pointer_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
