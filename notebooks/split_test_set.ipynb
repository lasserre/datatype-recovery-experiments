{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls ~/trained_models/\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 20)   # JSON columns make things look weird in notebook without this\n",
    "\n",
    "from datatype_recovery.models.dataset import load_dataset_from_path\n",
    "from datatype_recovery.models.dataset.encoding import *\n",
    "\n",
    "\n",
    "dataset_path = Path.home()/'datasets/tydamin_inmem'\n",
    "\n",
    "# model_path = Path.home()/'trained_models/dragon_5hops_5heads_3linear__trainset_new_ep50.pt'\n",
    "\n",
    "# eval_model_on_dataset(model_path, 'cuda:3', dataset_path)\n",
    "dataset = load_dataset_from_path(dataset_path)\n",
    "\n",
    "#df = dataset.read_vars_csv()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('TypeSeq_Debug').count().BinaryId\n",
    "#df.TypeSeq_Debug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is 1,556,212\n",
      "Test set has 155,619 samples (10.0%)\n",
      "Train set has 1,400,592 samples (90.0%)\n",
      "1 samples unused due to batch alignment (batch_size = 3)\n"
     ]
    }
   ],
   "source": [
    "from datatype_recovery.models.training import split_train_test\n",
    "\n",
    "train_indices, test_indices = split_train_test(len(dataset), batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test set: 100%|██████████| 155619/155619 [00:22<00:00, 6929.45it/s]\n",
      "Loading training set: 100%|██████████| 1400592/1400592 [02:56<00:00, 7931.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_set = [x for x in tqdm(Subset(dataset, list(test_indices)), desc='Loading test set')]\n",
    "train_set = [x for x in tqdm(Subset(dataset, list(train_indices)), desc='Loading training set')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset.collate(test_set), Path.cwd()/'test2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[5073407, 86], edge_index=[2, 9986088], edge_attr=[9986088, 26], varid=[155619], num_other_vars=[155619], y=[155619, 22]),\n",
       " {'x': tensor([      0,       5,      66,  ..., 5073184, 5073298, 5073407]),\n",
       "  'edge_index': tensor([      0,       8,     130,  ..., 9985646, 9985872, 9986088]),\n",
       "  'edge_attr': tensor([      0,       8,     130,  ..., 9985646, 9985872, 9986088]),\n",
       "  'varid': tensor([     0,      1,      2,  ..., 155617, 155618, 155619]),\n",
       "  'num_other_vars': tensor([     0,      1,      2,  ..., 155617, 155618, 155619]),\n",
       "  'y': tensor([     0,      1,      2,  ..., 155617, 155618, 155619])})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.load(Path.cwd()/'test2.pt')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5073407, 86], edge_index=[2, 9986088], edge_attr=[9986088, 26], varid=[155619], num_other_vars=[155619], y=[155619, 22])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class DefaultInMem(InMemoryDataset):\n",
    "    '''\n",
    "    Generic InMemoryDataset that saves/loads a list of Data objects\n",
    "    '''\n",
    "    def __init__(self, root, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        super().__init__(root, transform)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def process(self):\n",
    "        self.save(self.data_list, self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DefaultInMem(155619)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = DefaultInMem('testset', test_set)\n",
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[13, 86], edge_index=[2, 24], edge_attr=[24, 26], varid=[4], num_other_vars=[1], y=[1, 22])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
